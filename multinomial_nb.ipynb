{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-14T00:50:47.306500200Z",
     "start_time": "2025-11-14T00:50:47.304994400Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "import math\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from typing import List, Dict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def preprocess_text(text: str) -> str:\n",
    "    # простая предобработка lower + оставить буквы/цифры/проценты + нормализация пробелов\n",
    "    text = (text or \"\").lower()\n",
    "    text = re.sub(r\"[^а-яa-z0-9%]+\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def tokenize(text: str):\n",
    "    return preprocess_text(text).split()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-14T00:50:49.507794Z",
     "start_time": "2025-11-14T00:50:49.505287300Z"
    }
   },
   "id": "7e19e02ae8d35aaf"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл phrases_labels.csv успешно загружен.\n",
      "\n",
      "=== РЕЗУЛЬТАТЫ ===\n",
      "Train size: 82\n",
      "Test size: 21\n",
      "Accuracy: 0.6190476190476191\n",
      "\n",
      "Confusion matrix:\n",
      "('not_spam', 'spam'): 7\n",
      "('spam', 'spam'): 11\n",
      "('spam', 'not_spam'): 1\n",
      "('not_spam', 'not_spam'): 2\n",
      "\n",
      "Ошибки (если были):\n",
      "TEXT: ответьте, пожалуйста\n",
      "  true = not_spam, pred = spam\n",
      "\n",
      "TEXT: пожалуйста подтвердите\n",
      "  true = not_spam, pred = spam\n",
      "\n",
      "TEXT: акт выполненных работ\n",
      "  true = not_spam, pred = spam\n",
      "\n",
      "TEXT: работа на дому\n",
      "  true = spam, pred = not_spam\n",
      "\n",
      "TEXT: совместная работа\n",
      "  true = not_spam, pred = spam\n",
      "\n",
      "TEXT: план работ\n",
      "  true = not_spam, pred = spam\n",
      "\n",
      "TEXT: предлагаю встретиться\n",
      "  true = not_spam, pred = spam\n",
      "\n",
      "TEXT: версия релиза\n",
      "  true = not_spam, pred = spam\n"
     ]
    }
   ],
   "source": [
    "class MultinomialNaiveBayes:\n",
    "    def __init__(self, alpha: float = 1.0):\n",
    "        self.alpha = float(alpha)\n",
    "        self.vocab = set()\n",
    "        self.class_doc_counts = Counter()\n",
    "        self.class_token_counts = defaultdict(Counter)\n",
    "        self.class_total_tokens = Counter()\n",
    "        self.class_log_prior = {}\n",
    "        self.class_log_likelihood = {}\n",
    "        self.classes = []\n",
    "        self.trained = False\n",
    "\n",
    "    def fit(self, texts, labels):\n",
    "        # сбрасываем прежние данные\n",
    "        self.vocab.clear()\n",
    "        self.class_doc_counts = Counter()\n",
    "        self.class_token_counts = defaultdict(Counter)\n",
    "        self.class_total_tokens = Counter()\n",
    "        self.class_log_prior = {}\n",
    "        self.class_log_likelihood = {}\n",
    "        self.classes = []\n",
    "\n",
    "        for text, label in zip(texts, labels):\n",
    "            self.class_doc_counts[label] += 1\n",
    "            tokens = tokenize(text)\n",
    "            for t in tokens:\n",
    "                self.vocab.add(t)\n",
    "                self.class_token_counts[label][t] += 1\n",
    "                self.class_total_tokens[label] += 1\n",
    "\n",
    "        if not self.class_doc_counts:\n",
    "            raise ValueError(\"Нет обучающих данных (labels пустые).\")\n",
    "\n",
    "        self.classes = list(self.class_doc_counts.keys())\n",
    "        N = sum(self.class_doc_counts.values())\n",
    "\n",
    "        self.class_log_prior = {c: math.log(self.class_doc_counts[c] / N) for c in self.classes}\n",
    "\n",
    "        V = len(self.vocab)\n",
    "        if V == 0:\n",
    "            self.class_log_likelihood = {c: {} for c in self.classes}\n",
    "            self.trained = True\n",
    "            return\n",
    "\n",
    "        for c in self.classes:\n",
    "            denom = self.class_total_tokens[c] + self.alpha * V\n",
    "            probs = {}\n",
    "            for w in self.vocab:\n",
    "                num = self.class_token_counts[c].get(w, 0) + self.alpha\n",
    "                probs[w] = math.log(num / denom)\n",
    "            self.class_log_likelihood[c] = probs\n",
    "\n",
    "        self.trained = True\n",
    "\n",
    "    def _score(self, text, c):\n",
    "        if not self.trained:\n",
    "            raise RuntimeError(\"Модель не обучена. Вызовите fit() перед predict()\")\n",
    "        tokens = tokenize(text)\n",
    "        if not tokens:\n",
    "            return -1e9\n",
    "        counts = Counter(tokens)\n",
    "        logp = self.class_log_prior.get(c, math.log(1e-12))\n",
    "        V = len(self.vocab)\n",
    "        denom = self.class_total_tokens[c] + self.alpha * V\n",
    "        unseen_logp = math.log(self.alpha / denom) if V > 0 else math.log(1.0)\n",
    "        for w, cnt in counts.items():\n",
    "            if V > 0 and w in self.vocab:\n",
    "                logp += cnt * self.class_log_likelihood[c].get(w, unseen_logp)\n",
    "            else:\n",
    "                logp += cnt * unseen_logp\n",
    "        return logp\n",
    "\n",
    "    def predict(self, texts):\n",
    "        # texts: str или iterable[str]\n",
    "        single = False\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "            single = True\n",
    "        preds = []\n",
    "        for text in texts:\n",
    "            scores = {c: self._score(text, c) for c in self.classes}\n",
    "            pred = max(scores, key=scores.get)\n",
    "            preds.append(pred)\n",
    "        return preds[0] if single else preds\n",
    "\n",
    "    def predict_proba(self, texts):\n",
    "        # возвращаем нормализованные вероятности - принимает str или list[str]\n",
    "        single = False\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "            single = True\n",
    "        results = []\n",
    "        for text in texts:\n",
    "            scores = {c: self._score(text, c) for c in self.classes}\n",
    "            maxs = max(scores.values())\n",
    "            exps = {c: math.exp(scores[c] - maxs) for c in scores}\n",
    "            s = sum(exps.values())\n",
    "            probs = {c: exps[c] / s for c in exps}\n",
    "            results.append(probs)\n",
    "        return results[0] if single else results\n",
    "    \n",
    "    # ---- не обяз ----\n",
    "    def save(self, path: str):\n",
    "        \"\"\"Сохранить обученный объект модели в файл\"\"\"\n",
    "        with open(path, \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"alpha\": self.alpha,\n",
    "                \"vocab\": self.vocab,\n",
    "                \"class_doc_counts\": self.class_doc_counts,\n",
    "                \"class_token_counts\": self.class_token_counts,\n",
    "                \"class_total_tokens\": self.class_total_tokens,\n",
    "                \"class_log_prior\": self.class_log_prior,\n",
    "                \"class_log_likelihood\": self.class_log_likelihood,\n",
    "                \"classes\": self.classes,\n",
    "                \"trained\": self.trained\n",
    "            }, f)\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, path: str):\n",
    "        \"\"\"Загрузить модель из файла - возвращает экземпляр MultinomialNaiveBayes.\"\"\"\n",
    "        with open(path, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "        obj = cls(alpha=data.get(\"alpha\", 1.0))\n",
    "        obj.vocab = data.get(\"vocab\", set())\n",
    "        obj.class_doc_counts = data.get(\"class_doc_counts\", Counter())\n",
    "        obj.class_token_counts = data.get(\"class_token_counts\", defaultdict(Counter))\n",
    "        obj.class_total_tokens = data.get(\"class_total_tokens\", Counter())\n",
    "        obj.class_log_prior = data.get(\"class_log_prior\", {})\n",
    "        obj.class_log_likelihood = data.get(\"class_log_likelihood\", {})\n",
    "        obj.classes = data.get(\"classes\", [])\n",
    "        obj.trained = data.get(\"trained\", False)\n",
    "        return obj\n",
    "    \n",
    "    def train_and_evaluate(self,\n",
    "           texts: List[str],\n",
    "           labels: List[str],\n",
    "           test_size: float = 0.2,\n",
    "           random_state: int = 1,\n",
    "           return_misclassified: int = 20\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        делим данные на train/test\n",
    "        вызываем fit\n",
    "        делаем предсказания на тесте\n",
    "        возвращаем metrics: accuracy, confusion_matrix, misclassified_examples\n",
    "        \"\"\"\n",
    "        if not (0.0 < test_size < 1.0):\n",
    "            raise ValueError(\"test_size должен быть в (0,1)\")\n",
    "\n",
    "        # prepare indices\n",
    "        n = len(texts)\n",
    "        indices = list(range(n))\n",
    "        random.seed(random_state)\n",
    "        random.shuffle(indices)\n",
    "        split = int(n * (1 - test_size))\n",
    "        train_idx = indices[:split]\n",
    "        test_idx = indices[split:]\n",
    "\n",
    "        X_train = [texts[i] for i in train_idx]\n",
    "        y_train = [labels[i] for i in train_idx]\n",
    "        X_test = [texts[i] for i in test_idx]\n",
    "        y_test = [labels[i] for i in test_idx]\n",
    "\n",
    "        # train\n",
    "        self.fit(X_train, y_train)\n",
    "\n",
    "        # predict\n",
    "        preds = self.predict(X_test)\n",
    "\n",
    "        # accuracy\n",
    "        correct = sum(1 for p, t in zip(preds, y_test) if p == t)\n",
    "        accuracy = correct / len(y_test) if y_test else None\n",
    "\n",
    "        conf = Counter()\n",
    "        for true, pred in zip(y_test, preds):\n",
    "            conf[(true, pred)] += 1\n",
    "\n",
    "        mis = []\n",
    "        for tx, tr, pr in zip(X_test, y_test, preds):\n",
    "            if tr != pr and len(mis) < return_misclassified:\n",
    "                mis.append({\"text\": tx, \"true\": tr, \"pred\": pr})\n",
    "\n",
    "        return {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"confusion\": dict(conf),\n",
    "            \"n_test\": len(y_test),\n",
    "            \"n_train\": len(y_train),\n",
    "            \"misclassified\": mis\n",
    "        }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # --- загрузка датасета ---\n",
    "    try:\n",
    "        df = pd.read_csv(\"phrases_labels.csv\", encoding=\"utf-8\")\n",
    "        print(\"Файл phrases_labels.csv успешно загружен.\")\n",
    "\n",
    "        # нормализация названий колонок\n",
    "        if not {\"text\", \"label\"}.issubset(df.columns):\n",
    "            if {\"phrase\", \"label\"}.issubset(df.columns):\n",
    "                df = df.rename(columns={\"phrase\": \"text\"})\n",
    "            elif {\"phrase\", \"tag\"}.issubset(df.columns):\n",
    "                df = df.rename(columns={\"phrase\": \"text\", \"tag\": \"label\"})\n",
    "            else:\n",
    "                raise ValueError(\"CSV должен содержать 'text' и 'label' или ('phrase','label').\")\n",
    "\n",
    "        # --- подготовка данных ---\n",
    "        texts = df[\"text\"].tolist()\n",
    "        labels = df[\"label\"].tolist()\n",
    "\n",
    "        # --- создаем модель ---\n",
    "        model = MultinomialNaiveBayes(alpha=1.0)\n",
    "\n",
    "        # --- полноценное обучение + оценка ---\n",
    "        report = model.train_and_evaluate(\n",
    "            texts=texts,\n",
    "            labels=labels,\n",
    "            test_size=0.2,\n",
    "            random_state=42,\n",
    "            return_misclassified=10\n",
    "        )\n",
    "\n",
    "        print(\"\\n=== РЕЗУЛЬТАТЫ ===\")\n",
    "        print(\"Train size:\", report[\"n_train\"])\n",
    "        print(\"Test size:\", report[\"n_test\"])\n",
    "        print(\"Accuracy:\", report[\"accuracy\"])\n",
    "        print(\"\\nConfusion matrix:\")\n",
    "        for k, v in report[\"confusion\"].items():\n",
    "            print(f\"{k}: {v}\")\n",
    "\n",
    "        print(\"\\nОшибки (если были):\")\n",
    "        for item in report[\"misclassified\"]:\n",
    "            print(f\"TEXT: {item['text']}\")\n",
    "            print(f\"  true = {item['true']}, pred = {item['pred']}\")\n",
    "            print()\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"Файл phrases_labels.csv не найден в этой директории.\")\n",
    "    except Exception as exc:\n",
    "        print(\"Ошибка:\", exc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-14T00:51:30.570870400Z",
     "start_time": "2025-11-14T00:51:30.555470700Z"
    }
   },
   "id": "c8606aeaa5c4d620"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
